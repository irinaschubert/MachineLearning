{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# define project path\n",
    "projectpath = 'projectpath'\n",
    "train_data_csv = projectpath + 'train.csv'\n",
    "test_data_csv = projectpath + 'test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_data_csv,header=None)\n",
    "\n",
    "# save target values with index into new dataframe 'labels'\n",
    "df_labels = pd.read_csv(train_data_csv, names=['target'], header=None, usecols=[1])\n",
    "\n",
    "# save as array\n",
    "df_labels = df_labels['target'].values\n",
    "\n",
    "# save data into new dataframe 'training_data'\n",
    "df_training_data_raw = df_train.drop(columns=[0,1])\n",
    "\n",
    "# split dataset into train (80%) and test data (20%); random_state=1 makes it reproducible (could be any number); stratify ensures that the proportion stays in test and training data sets\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(df_training_data_raw, df_labels, test_size=0.2, random_state=1, shuffle=True, stratify=df_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a KNN model and use it with GridSearchCV\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=50)\n",
    "decision_tree_model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model and use it with GridSearchCV\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# create a dictionary of all values we want to test\n",
    "param_grid = {'max_depth': np.arange(1, 50)}\n",
    "\n",
    "# use gridsearch to test all values\n",
    "optimal_model = GridSearchCV(decision_tree_model, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to data\n",
    "optimal_model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 36}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check top performing value for n\n",
    "optimal_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068242521367521"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mean score for the top performing value of n\n",
    "optimal_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see how model performs on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'F' 'J' 'J' 'C' 'J' 'B' 'D' 'G' 'J' 'J' 'C' 'G' 'C' 'G' 'C' 'H' 'E'\n",
      " 'D' 'G' 'I' 'H' 'D' 'E' 'E' 'B' 'H' 'B' 'E' 'H' 'H' 'B' 'J' 'D' 'I' 'F'\n",
      " 'J' 'B' 'A' 'A' 'E' 'H' 'I' 'I' 'I' 'D' 'A' 'H' 'E' 'A' 'I' 'B' 'D' 'J'\n",
      " 'B' 'D' 'B' 'D' 'B' 'G' 'H' 'G' 'A' 'A' 'B' 'C' 'E' 'I' 'B' 'J' 'H' 'A'\n",
      " 'I' 'I' 'A' 'H' 'F' 'J' 'D' 'F' 'G' 'B' 'G' 'G' 'I' 'E' 'F' 'B' 'B' 'H'\n",
      " 'A' 'E' 'F' 'D' 'A' 'H' 'J' 'I' 'J' 'F']\n"
     ]
    }
   ],
   "source": [
    "# predict the labels for the test slice\n",
    "labels_pred = optimal_model.predict(data_test)\n",
    "print(labels_pred[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8125\n",
      "Precision: [0.8245614  0.8057971  0.84453228 0.79923274 0.79004038 0.8342246\n",
      " 0.80810811 0.80559254 0.79434447 0.81878307]\n",
      "Recall: [0.81575434 0.7423231  0.85695187 0.83444593 0.78371162 0.83311081\n",
      " 0.79839786 0.80774366 0.82510013 0.82754011]\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy for the test data\n",
    "print(\"Accuracy:\", metrics.accuracy_score(labels_test, labels_pred))\n",
    "# check the precision for the test data\n",
    "print(\"Precision:\",metrics.precision_score(labels_test, labels_pred, average=None))\n",
    "# check the recall for the test data\n",
    "print(\"Recall:\",metrics.recall_score(labels_test, labels_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H' 'B' 'A' 'B' 'B' 'D' 'I' 'B' 'A' 'I' 'A' 'A' 'A' 'G' 'A' 'A' 'A' 'E'\n",
      " 'A' 'A' 'A' 'I' 'A' 'I' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'I' 'A'\n",
      " 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A'\n",
      " 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'D' 'J' 'H' 'A' 'A' 'A' 'A' 'A' 'A' 'A'\n",
      " 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'J' 'C' 'I' 'A' 'A' 'A' 'A' 'A' 'J'\n",
      " 'A' 'A' 'B' 'A' 'H' 'A' 'A' 'A' 'A' 'A']\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(test_data_csv, sep=',', header=None)\n",
    "test_data_new = df_test.drop(columns=[0])\n",
    "# predict values for new data\n",
    "predicted = optimal_model.predict(test_data_new)\n",
    "print(predicted[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.DataFrame(columns=['id','target'])\n",
    "predicted = pd.Series(predicted)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id target\n",
       "0   0      H\n",
       "1   1      B\n",
       "2   2      A\n",
       "3   3      B\n",
       "4   4      B"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add calculated target values to csv and format for submission\n",
    "df_submission['target'] = predicted\n",
    "df_submission['id'] = df_submission.index\n",
    "submission_file = projectpath + 'submission.csv'\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(submission_file, index=False, columns=['id','target'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
